{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG: Retrieval Augmented Generation.\n",
    "- Large language models (LLMs) have a limited context size.\n",
    "- TLDR\n",
    "- Not all context is relevant to a given question\n",
    "- Query -> Search -> Results -> (LLM) -> Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword VS Semantic Search \n",
    "![Vector](https://blog.dataiku.com/hs-fs/hubfs/dftt%202.webp?width=1346&height=632&name=dftt%202.webp)\n",
    "\n",
    "from https://blog.dataiku.com/semantic-search-an-overlooked-nlp-superpower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Emb_search](figures/emb_search.png)\n",
    "\n",
    "from https://sreent.medium.com/llms-embeddings-and-vector-search-d4bd9362df56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install -qU  markdownify  langchain-upstage rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "# UPSTAGE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most powerful solar embedding\n",
    "![Solar Embedding](figures/solar_emb.jpeg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4096)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_upstage import UpstageEmbeddings\n",
    "# 근데 이건 내가 아는 embedding이랑 다른가? 검색 엔진에서 어떻게 쓰이는 거지? 그냥 유사도가 아니라? 나는 topic modeling 할 때 썼던 것 같음\n",
    "\n",
    "embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "embeddings = embeddings_model.embed_documents(\n",
    "    [\n",
    "        \"What is the best season to visit Korea?\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 1. load doc (done), 2. chunking, splits, 3. embeding - indexing, 4. retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageLayoutAnalysisLoader\n",
    "\n",
    "\n",
    "layzer = UpstageLayoutAnalysisLoader(\"pdfs/kim-tse-2008.pdf\", output_type=\"html\")\n",
    "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "docs = layzer.load()  # or layzer.lazy_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: 125\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "\n",
    "# 2. Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_language( # chunk_size는 100~500~1000개가 괜찮음\n",
    "    chunk_size=1000, chunk_overlap=100, language=Language.HTML\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(\"Splits:\", len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_chroma\n",
      "  Using cached langchain_chroma-0.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting chromadb<0.6.0,>=0.4.0 (from langchain_chroma)\n",
      "  Using cached chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting fastapi<1,>=0.95.2 (from langchain_chroma)\n",
      "  Using cached fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.40 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_chroma) (0.1.52)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain_chroma) (1.26.4)\n",
      "Collecting build>=1.0.3 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.7.1)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached chroma-hnswlib-0.7.3.tar.gz (31 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.11.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached onnxruntime-1.17.3-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached grpcio-1.63.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached bcrypt-4.1.3-cp39-abi3-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (8.3.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached mmh3-4.1.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.10.3)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi<1,>=0.95.2->langchain_chroma)\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi<1,>=0.95.2->langchain_chroma)\n",
      "  Using cached fastapi_cli-0.0.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.27.0)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (3.1.4)\n",
      "Collecting python-multipart>=0.0.7 (from fastapi<1,>=0.95.2->langchain_chroma)\n",
      "  Using cached python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi<1,>=0.95.2->langchain_chroma)\n",
      "  Using cached ujson-5.10.0-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi<1,>=0.95.2->langchain_chroma)\n",
      "  Using cached email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3,>=0.1.40->langchain_chroma) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3,>=0.1.40->langchain_chroma) (0.1.59)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3,>=0.1.40->langchain_chroma) (23.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.4.6)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain_chroma)\n",
      "  Using cached dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: idna>=2.0.0 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain_chroma) (3.7)\n",
      "Requirement already satisfied: anyio in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2>=2.11.2->fastapi<1,>=0.95.2->langchain_chroma) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain_chroma) (2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.2.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached protobuf-5.26.1-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached importlib_metadata-7.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting setuptools>=16.0 (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.3.2)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached httptools-0.6.1-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.0.1)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached watchfiles-0.21.0-cp312-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached websockets-12.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached zipp-3.18.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hy lee\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.18.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Using cached langchain_chroma-0.1.1-py3-none-any.whl (8.5 kB)\n",
      "Using cached chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
      "Using cached fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "Using cached bcrypt-4.1.3-cp39-abi3-win_amd64.whl (158 kB)\n",
      "Using cached build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Using cached fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
      "Using cached grpcio-1.63.0-cp312-cp312-win_amd64.whl (3.9 MB)\n",
      "Using cached kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached mmh3-4.1.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Using cached onnxruntime-1.17.3-cp312-cp312-win_amd64.whl (5.6 MB)\n",
      "Using cached opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Using cached opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
      "Using cached opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "Using cached posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "Using cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Using cached ujson-5.10.0-cp312-cp312-win_amd64.whl (42 kB)\n",
      "Using cached uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "Using cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached httptools-0.6.1-cp312-cp312-win_amd64.whl (55 kB)\n",
      "Using cached huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "Using cached importlib_metadata-7.0.0-py3-none-any.whl (23 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached watchfiles-0.21.0-cp312-none-win_amd64.whl (280 kB)\n",
      "Using cached websockets-12.0-cp312-cp312-win_amd64.whl (124 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
      "Using cached wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Using cached zipp-3.18.2-py3-none-any.whl (8.3 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Building wheels for collected packages: chroma-hnswlib\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): started\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml): finished with status 'error'\n",
      "Failed to build chroma-hnswlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for chroma-hnswlib (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [5 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_ext\n",
      "      building 'hnswlib' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for chroma-hnswlib\n",
      "ERROR: Could not build wheels for chroma-hnswlib, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "! pip3 install langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_chroma'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_chroma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Chroma \u001b[38;5;66;03m# 이걸로 embed\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 3. Embed & indexing\u001b[39;00m\n\u001b[0;32m      4\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[0;32m      5\u001b[0m     documents\u001b[38;5;241m=\u001b[39msplits,\n\u001b[0;32m      6\u001b[0m     embedding\u001b[38;5;241m=\u001b[39mUpstageEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolar-embedding-1-large\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_chroma'"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma # 이걸로 embed\n",
    "\n",
    "# 3. Embed & indexing\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=UpstageEmbeddings(model=\"solar-embedding-1-large\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "<p id='48' style='font-size:16px'>Similar in spirit to change classification is work that<br>classif\n"
     ]
    }
   ],
   "source": [
    "# 4. retrive\n",
    "retriever = vectorstore.as_retriever()\n",
    "result_docs = retriever.invoke(\"What is Bug Classification?\")\n",
    "print(len(result_docs))\n",
    "print(result_docs[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresult_docs\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result_docs' is not defined"
     ]
    }
   ],
   "source": [
    "result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "\n",
    "llm = ChatUpstage()\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Please provide most correct answer from the following context. \n",
    "    If the answer is not present in the context, please write \"The information is not present in the context.\"\n",
    "    ---\n",
    "    Question: {question}\n",
    "    ---\n",
    "    Context: {Context}\n",
    "    \"\"\"\n",
    ")\n",
    "chain = prompt_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bug classification is a process that involves extracting keywords from bug reports or software maintenance requests and using them as features to train a machine learning classifier. The goal of this classification is to place a bug report into a specific category or to find the developer best suited to fix a bug. This work, along with change classification, highlights the potential of using machine learning techniques in software engineering. If an existing concern such as assigning bugs to developers can be recast as a classification problem, then it is possible to leverage the large collection of data stored in bug tracking and SCM systems.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"What is bug classficiation?\", \"Context\": result_docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise: Hybrid\n",
    "Sometimes keyword search can be useful. Design a system that does keyword and semantic search, then combine the results. Use them as context for your RAG."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
